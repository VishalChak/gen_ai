{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75554007-1d4c-4303-b18b-1fc2e18d5717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff77b037f3f47d9a09c6227edcb3c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0503402c38ea44c88a1ef97a2181c56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### sample dataset\n",
    "\n",
    "from datasets import Dataset\n",
    "data = {\n",
    "    \"prompt\": [\n",
    "        \"What is the capital of France?\",\n",
    "        \"Define gravity.\",\n",
    "        \"Who wrote Hamlet?\"\n",
    "    ],\n",
    "    \"response\": [\n",
    "        \"The capital of France is Paris.\",\n",
    "        \"Gravity is a force that attracts two bodies toward each other.\",\n",
    "        \"William Shakespeare wrote Hamlet.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset['train']\n",
    "eval_dataset = split_dataset['test']\n",
    "\n",
    "\n",
    "def format(example):\n",
    "    return {\"text\": f\"### Instruction:\\n{example['prompt']}\\n\\n### Response:\\n{example['response']}\"}\n",
    "\n",
    "train_dataset = train_dataset.map(format)\n",
    "eval_dataset = eval_dataset.map(format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9bbce6-76a1-4fae-a4c4-8065ac3ffed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load model and tokenizer\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = \"sshleifer/tiny-gpt2\" #Tiny demo model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model= AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c84e2d57-5df3-49bb-b341-be3a1daf8111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 64 || all params: 102,778 || trainable%: 0.0623\n"
     ]
    }
   ],
   "source": [
    "### Apply QLORA and PEFT\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 4,\n",
    "    lora_alpha = 8,\n",
    "    target_modules = [\"c_attn\"],  ### for gp2 architecture\n",
    "    lora_dropout = 0.05,\n",
    "    task_type= TaskType.CAUSAL_LM    \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c823608-f1d2-499f-8c61-8b77cbe6eb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a26f64f9084c268cf7728a15cd4a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc9dde4f465427c8ea0d2129584b835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/home/vishal/envs/rnd/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.401100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/envs/rnd/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=10.400525410970053, metrics={'train_runtime': 3.0599, 'train_samples_per_second': 1.961, 'train_steps_per_second': 0.98, 'total_flos': 497664.0, 'train_loss': 10.400525410970053, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Tokenizer and training configration\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\" ,max_length=64)\n",
    "\n",
    "train_dataset= train_dataset.map(tokenize)\n",
    "eval_dataset = eval_dataset.map(tokenize)\n",
    "\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir = \"qlora_out\",\n",
    "    per_device_train_batch_size = 2,\n",
    "    num_train_epochs = 3,\n",
    "    logging_steps=1,\n",
    "    save_steps= 2,\n",
    "    save_total_limit = 2,\n",
    "    fp16=False ##CPU only\n",
    "    )\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer , mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_arguments,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    data_collator= data_collator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "291a7c80-ace5-4b3e-8e36-0073c261d08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qlora_out/qlora-tiny-model/tokenizer_config.json',\n",
       " 'qlora_out/qlora-tiny-model/special_tokens_map.json',\n",
       " 'qlora_out/qlora-tiny-model/vocab.json',\n",
       " 'qlora_out/qlora-tiny-model/merges.txt',\n",
       " 'qlora_out/qlora-tiny-model/added_tokens.json',\n",
       " 'qlora_out/qlora-tiny-model/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"qlora_out/qlora-tiny-model\")\n",
    "tokenizer.save_pretrained(\"qlora_out/qlora-tiny-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b715b636-846f-4c51-bc84-7646dbdca3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "### Use pipline for inferanceing\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model =\"qlora_out/qlora-tiny-model\", tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c909f8b-fc41-438a-9fa3-5c7b48d019ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Who discovered penicillin?\n",
      "\n",
      "### Response:\n",
      "hibit reviewing heirJD Rh subst Daniel vendors stairs Motorola stairs Motorolaatisf subst Rh Brew reborn TAhibitpress confir dispatch Hancock stairs credibility004 Habitoother Amph Money TA autonomy dispatch dispatchikendit heir antibioticpress confir Hancock autonomy Hancock reborn subst Amph confir scalp ProbRocket\n"
     ]
    }
   ],
   "source": [
    "result = pipe(\"### Instruction:\\nWho discovered penicillin?\\n\\n### Response:\\n\", max_new_tokens=50)\n",
    "print(result[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07f247-f408-42b9-a001-4c6a7acc7bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
