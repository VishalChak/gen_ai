{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "36462735-2069-4530-993a-7c494898c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a380c633-16a6-4668-9589-a1adbec46d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model\n",
    "\n",
    "model_name = \"sshleifer/tiny-gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  ## in case of tiny-gpt2\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.config.pad_token_id = tokenizer.eos_token_id   ## in case of tiny-gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "537de5e8-6ecd-4ec8-8033-3d38b5337aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/envs/rnd/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Lora Configration\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 2, \n",
    "    lora_alpha = 8,\n",
    "    lora_dropout = 0.05\n",
    "    task_type = TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ec74bc04-9a5c-4b0f-8ba6-49fffb63f5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac4ab7c43de4c09b3400706325f50ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9778d786bbba4c24924506dfa4dfd618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "    {\"text\": \"### Instruction: Say hello\\n### Response: Hello there!\"},\n",
    "    {\"text\": \"### Instruction: What's the capital of France?\\n### Response: The capital of France is Paris.\"},\n",
    "    {\"text\": \"### Instruction: Translate 'Good morning' to Spanish\\n### Response: Buenos días.\"},\n",
    "    {\"text\": \"### Instruction: Add 5 and 7\\n### Response: The result is 12.\"},\n",
    "    {\"text\": \"### Instruction: List three colors\\n### Response: Red, blue, and green.\"},\n",
    "    {\"text\": \"### Instruction: Who wrote 'Hamlet'?\\n### Response: William Shakespeare wrote 'Hamlet'.\"},\n",
    "    {\"text\": \"### Instruction: Convert 100 Celsius to Fahrenheit\\n### Response: 100°C is equal to 212°F.\"},\n",
    "    {\"text\": \"### Instruction: Name a programming language\\n### Response: Python.\"},\n",
    "    {\"text\": \"### Instruction: What's the square root of 64?\\n### Response: The square root of 64 is 8.\"},\n",
    "    {\"text\": \"### Instruction: Tell a joke\\n### Response: Why did the computer go to therapy? Because it had too many bytes!\"}\n",
    "]\n",
    "\n",
    "train_data = data[:-2]\n",
    "eval_data = data[-2:]\n",
    "\n",
    "train_data = Dataset.from_list(train_data)\n",
    "eval_data = Dataset.from_list(eval_data)\n",
    "\n",
    "train_dataset = train_data.map(lambda e: tokenizer(e[\"text\"], truncation=True, padding=\"max_length\", max_length=64))\n",
    "eval_dataset = eval_data.map(lambda e: tokenizer(e[\"text\"], truncation=True, padding=\"max_length\", max_length=64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d227153d-bc17-4654-a513-966924ca0911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8650/1916127289.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "### training Arguments and trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"lora_out\",\n",
    "    per_device_train_batch_size=2, num_train_epochs=3,\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",       # save after each epoch (default)\n",
    "    save_total_limit=3,          # keep only last 3 checkpoints to save disk space\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator= data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dc67ab72-412d-41ae-ba7f-535418e19374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10.240200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>10.247900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/envs/rnd/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/vishal/envs/rnd/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('lora_out/custom-tiny-gpt2/tokenizer_config.json',\n",
       " 'lora_out/custom-tiny-gpt2/special_tokens_map.json',\n",
       " 'lora_out/custom-tiny-gpt2/vocab.json',\n",
       " 'lora_out/custom-tiny-gpt2/merges.txt',\n",
       " 'lora_out/custom-tiny-gpt2/added_tokens.json',\n",
       " 'lora_out/custom-tiny-gpt2/tokenizer.json')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"lora_out/custom-tiny-gpt2\")\n",
    "tokenizer.save_pretrained(\"lora_out/custom-tiny-gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2bf25bf0-e86d-49a7-84c2-d00c842a15df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/envs/rnd/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 50122.37076443425\n"
     ]
    }
   ],
   "source": [
    "### model evaluations\n",
    "import math\n",
    "\n",
    "### perplexity\n",
    "eval_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "perplexity = math.exp(eval_loss)\n",
    "print(\"Perplexity:\", perplexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "03fae88c-7d22-4c99-8cdf-b5ded8614e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "### inferance  \n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "### load model \n",
    "\n",
    "trained_model_path  = \"lora_out/custom-tiny-gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(trained_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_model_path)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# test prompts (instructions)\n",
    "prompts = [\n",
    "    \"Say hello:\",\n",
    "    \"Translate 'Good morning' to Spanish:\",\n",
    "    \"Add 5 and 7:\"\n",
    "]\n",
    "\n",
    "# Reference answers\n",
    "references = [\n",
    "    \"Hello there!\",\n",
    "    \"Buenos días.\",\n",
    "    \"12\"\n",
    "]\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors= \"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        # inputs[\"input_ids\"],\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1\n",
    "        \n",
    "        # max_new_tokens = 50,\n",
    "        # do_sample = False  # deterministic output; set True for randomness\n",
    "    )\n",
    "    pred = tokenizer.decode(output[0], skip_special_tokens = True)\n",
    "    pred_text = pred[len(prompt):].strip()\n",
    "    predictions.append(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ce121716-e22b-4850-8b6d-bca14962b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Predictions:\", predictions)\n",
    "# print(\"References:\", references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb50a1c-47bc-47b6-a2f5-a7c29b831d76",
   "metadata": {},
   "source": [
    "#### Evaluation Metrices\n",
    "##### Bleu (Bilingual Evaluation Understudy):\n",
    "> Measures how many n-grams in the generated text match the reference, focusing on precision.\n",
    "##### ROUGE (Recall-Oriented Understudy for Gisting Evaluation):\n",
    "> Measures how much of the reference text is captured in the generated output, focusing on recall.\n",
    "##### METEOR (Metric for Evaluation of Translation with Explicit ORdering):\n",
    "> Combines precision, recall, synonym matching, and word order into a harmonic score for better semantic evaluation.\n",
    "##### Perplexity:\n",
    "> Evaluates a language model’s performance by computing the inverse probability of the test set, normalized by length—lower values mean less uncertainty in predicting the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0e266a40-10eb-4ceb-844e-22a07ac28387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c3192fa1894d53be54f44ae2ef1b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/vishal/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /home/vishal/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/vishal/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: {'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 15.0, 'translation_length': 105, 'reference_length': 7}\n",
      "ROUGE: {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n",
      "METEOR: {'meteor': np.float64(0.0)}\n"
     ]
    }
   ],
   "source": [
    "### evaluation\n",
    "\n",
    "bleu   = evaluate.load(\"bleu\")\n",
    "rouge  = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "\n",
    "bleu_result = bleu.compute(predictions=predictions, references=references)\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"BLEU:\", bleu_result)\n",
    "print(\"ROUGE:\", rouge_result)\n",
    "print(\"METEOR:\", meteor_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9510d25-edd0-44c9-9b15-ac7077a76fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd88848-1aa7-4f8c-b5f7-f608f785b22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62795b68-74ec-4d8f-b614-8b715709d4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
