{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa3950c-735e-4d33-b962-5d93cbfa5e07",
   "metadata": {},
   "source": [
    "### Lets understand the token of input promts that model use for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8031e7-1a07-4a9e-a263-a7fb66ca7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b51a2b-cba3-44c9-b0b2-41390263a617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47f987bf63e4c179a4f7993340ffce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map = \"cuda\",\n",
    "    torch_dtype= \"auto\",\n",
    "    trust_remote_code = True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6e32de9-d789-49a5-b73b-5e2838a98388",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt = \"<s> write an email apologizing to sarah for tragic garding misap. Example how it happened. it was not  <|assistant|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eda32a6a-85fa-45df-8ae8-c90dee0c78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the input promt\n",
    "input_ids = tokenizer(promt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3d12a54-9744-421f-b5d0-08e8f86110ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate teh text\n",
    "generated_output = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    max_new_tokens = 20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee241e77-89a8-4036-a970-8271c6d9e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>  write an email apologizing to sarah for tragic garding misap. Example how it happened. it was not  <|assistant|> Subject: Sincere Apologies for the Gardening Mishap\n",
      "\n",
      "Dear Sarah\n"
     ]
    }
   ],
   "source": [
    "## print the output\n",
    "print(tokenizer.decode(generated_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0c6e0f1-968d-4729-84ea-d0826e9ee841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 29871,  2436,   385,  4876, 27746,  5281,   304, 22887,   801,\n",
      "           363, 25305,   293, 17161,   292,  3984,   481, 29889,  8741,   920,\n",
      "           372,  9559, 29889,   372,   471,   451,   259, 32001]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## lets print input_ids\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3945fc7-aef0-4a50-9fe9-fdeeae82fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0') <s>\n",
      "tensor(29871, device='cuda:0') \n",
      "tensor(2436, device='cuda:0') write\n",
      "tensor(385, device='cuda:0') an\n",
      "tensor(4876, device='cuda:0') email\n",
      "tensor(27746, device='cuda:0') apolog\n",
      "tensor(5281, device='cuda:0') izing\n",
      "tensor(304, device='cuda:0') to\n",
      "tensor(22887, device='cuda:0') sar\n",
      "tensor(801, device='cuda:0') ah\n",
      "tensor(363, device='cuda:0') for\n",
      "tensor(25305, device='cuda:0') trag\n",
      "tensor(293, device='cuda:0') ic\n",
      "tensor(17161, device='cuda:0') gard\n",
      "tensor(292, device='cuda:0') ing\n",
      "tensor(3984, device='cuda:0') mis\n",
      "tensor(481, device='cuda:0') ap\n",
      "tensor(29889, device='cuda:0') .\n",
      "tensor(8741, device='cuda:0') Example\n",
      "tensor(920, device='cuda:0') how\n",
      "tensor(372, device='cuda:0') it\n",
      "tensor(9559, device='cuda:0') happened\n",
      "tensor(29889, device='cuda:0') .\n",
      "tensor(372, device='cuda:0') it\n",
      "tensor(471, device='cuda:0') was\n",
      "tensor(451, device='cuda:0') not\n",
      "tensor(259, device='cuda:0')  \n",
      "tensor(32001, device='cuda:0') <|assistant|>\n"
     ]
    }
   ],
   "source": [
    "for id in input_ids[0]:\n",
    "    print(id , tokenizer.decode(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d09e57-0b7f-4f47-a7f7-c9a5e8086d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
