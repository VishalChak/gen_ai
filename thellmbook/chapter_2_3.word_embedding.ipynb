{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce73a192-4e70-4f49-8e30-d8bd6ba0d702",
   "metadata": {},
   "source": [
    "### Word embedding beyoud LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f1680-7e2a-41b2-a8ba-8ae7134ee994",
   "metadata": {},
   "source": [
    "#### Using pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8656101f-b2a8-4ff3-a0fd-4b60855823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21396bc4-a6a5-4145-8b4c-6fc8d326e8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 1.0000001192092896),\n",
       " ('prince', 0.8236181139945984),\n",
       " ('queen', 0.7839042544364929),\n",
       " ('ii', 0.7746229767799377),\n",
       " ('emperor', 0.7736246585845947),\n",
       " ('son', 0.7667195200920105),\n",
       " ('uncle', 0.7627151012420654),\n",
       " ('kingdom', 0.7542161345481873),\n",
       " ('throne', 0.7539914846420288),\n",
       " ('brother', 0.7492412328720093),\n",
       " ('ruler', 0.7434254288673401)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([model['king']], topn=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde42de2-7579-4c60-a954-d703e8951393",
   "metadata": {},
   "source": [
    "### Training the song embedding model\n",
    "\n",
    "##### Lets assume a song is word embedding and a playlist is a sentence...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bb47f68-6017-4eed-b930-f4706e84dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib import request\n",
    "\n",
    "### get a playlist dataset file\n",
    "\n",
    "data =  request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724b4933-e7ab-4c0b-9535-6c720525dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parse the playlist dataset file . skip the first two \n",
    "## lines as they only contain meta data\n",
    "lines = data.read().decode(\"utf-8\").split(\"\\n\")[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a931551-2f29-4d14-bbb5-5b83682230ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove play list with less then two songs\n",
    "playlists = [s.strip().split() for s in lines if len(s.split()) > 1]\n",
    "\n",
    "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')\n",
    " # Parse the playlist dataset file. Skip the first two lines as\n",
    " # they only contain metadata\n",
    "lines = data.read().decode(\"utf-8\").split('\\n')[2:]\n",
    " # Remove playlists with only one song\n",
    "playlists = [s.rstrip().split() for s in lines if len(s.split()) >1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5afd8bb-dd90-4302-b525-a3465bc654d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load song metadata\n",
    "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
    "songs_file = songs_file.read().decode(\"utf-8\").split(\"\\n\")\n",
    "songs = [s.rstrip().split(\"\\t\") for s in songs_file]\n",
    "\n",
    "songs_df = pd.DataFrame(data=songs, columns=[\"id\", \"title\" , \"artist\"])\n",
    "songs_df = songs_df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58621e5e-1341-4e71-8534-167225df52ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist #1:\n",
      "  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '2', '42', '43', '44', '45', '46', '47', '48', '20', '49', '8', '50', '51', '52', '53', '54', '55', '56', '57', '25', '58', '59', '60', '61', '62', '3', '63', '64', '65', '66', '46', '47', '67', '2', '48', '68', '69', '70', '57', '50', '71', '72', '53', '73', '25', '74', '59', '20', '46', '75', '76', '77', '59', '20', '43'] \n",
      "\n",
      "Playlist #2:\n",
      "  ['78', '79', '80', '3', '62', '81', '14', '82', '48', '83', '84', '17', '85', '86', '87', '88', '74', '89', '90', '91', '4', '73', '62', '92', '17', '53', '59', '93', '94', '51', '50', '27', '95', '48', '96', '97', '98', '99', '100', '57', '101', '102', '25', '103', '3', '104', '105', '106', '107', '47', '108', '109', '110', '111', '112', '113', '25', '63', '62', '114', '115', '84', '116', '117', '118', '119', '120', '121', '122', '123', '50', '70', '71', '124', '17', '85', '14', '82', '48', '125', '47', '46', '72', '53', '25', '73', '4', '126', '59', '74', '20', '43', '127', '128', '129', '13', '82', '48', '130', '131', '132', '133', '134', '135', '136', '137', '59', '46', '138', '43', '20', '139', '140', '73', '57', '70', '141', '3', '1', '74', '142', '143', '144', '145', '48', '13', '25', '146', '50', '147', '126', '59', '20', '148', '149', '150', '151', '152', '56', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '60', '176', '51', '177', '178', '179', '180', '181', '182', '183', '184', '185', '57', '186', '187', '188', '189', '190', '191', '46', '192', '193', '194', '195', '196', '197', '198', '25', '199', '200', '49', '201', '100', '202', '203', '204', '205', '206', '207', '32', '208', '209', '210']\n"
     ]
    }
   ],
   "source": [
    "print( 'Playlist #1:\\n ', playlists[0], '\\n')\n",
    "print( 'Playlist #2:\\n ', playlists[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2bcbe30-4005-478d-b150-d9f25b66454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###   lets train model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(playlists, vector_size=32, window=20, negative=50, \n",
    "                 min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0de87a60-6264-4291-bb40-c4ca4e7dd8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6658', 0.9981025457382202),\n",
       " ('11473', 0.9975206851959229),\n",
       " ('3126', 0.9971314668655396),\n",
       " ('3167', 0.9969710111618042),\n",
       " ('5586', 0.9967140555381775),\n",
       " ('6624', 0.9963540434837341),\n",
       " ('3094', 0.9963253736495972),\n",
       " ('10105', 0.9952881932258606),\n",
       " ('10084', 0.9951165914535522),\n",
       " ('2849', 0.9950700998306274)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_id = 2172\n",
    "model.wv.most_similar(positive=str(song_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22b8db2b-ea1f-4136-811e-ea8a6e68a0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title     Fade To Black\n",
      "artist        Metallica\n",
      "Name: 2172 , dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(songs_df.iloc[2172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0249ae6-dc5b-467a-999d-8c8123daa350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_recommendations(song_id):\n",
    "    similar_songs = np.array(model.wv.most_similar(positive=str(song_id),\n",
    "                                                   topn=5))[:,0]\n",
    "    return songs_df.iloc[similar_songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "120ede39-f778-479b-aaed-9f4391bdc817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>(Bang Your Head) Metal Health</td>\n",
       "      <td>Quiet Riot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11473</th>\n",
       "      <td>Little Guitars</td>\n",
       "      <td>Van Halen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>Sammy Hagar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>Unchained</td>\n",
       "      <td>Van Halen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>The Last In Line</td>\n",
       "      <td>Dio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title       artist\n",
       "id                                                \n",
       "6658    (Bang Your Head) Metal Health   Quiet Riot\n",
       "11473                  Little Guitars    Van Halen\n",
       "3126                      Heavy Metal  Sammy Hagar\n",
       "3167                        Unchained    Van Halen\n",
       "5586                 The Last In Line          Dio"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_recommendations(2172)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f06ad-48d6-4a49-9eab-5e96f275429e",
   "metadata": {},
   "source": [
    "### Summary\n",
    "1. In this chapter, we have covered LLM tokens, tokenizers, and useful approaches to using token embeddings. This prepares us to start looking closer at language models in the next chapter, and also opens the door to learn about how embeddings are used beyond language models.\n",
    "2. We explored how tokenizers are the first step in processing input to an LLM, transforming raw textual input into token IDs. Common tokenization schemes include breaking text down into words, subword tokens, characters, or bytes, depending on the specific requirements of a given application.\n",
    "3. A tour of real-world pretrained tokenizers (from BERT to GPT-2, GPT-4, and other models) showed us areas where some tokenizers are better (e.g., preserving information like capitalization, newlines, or tokens in other languages) and other areas where tokenizers are just different from each other (e.g., how they break down certain words).\n",
    "4. Three of the major tokenizer design decisions are the tokenizer algorithm (e.g., BPE, WordPiece, SentencePiece), tokenization parameters (including vocabulary size, special tokens, capitalization, treatment of capitalization and different languages), and the dataset the tokenizer is trained on.\n",
    "5. Language models are also creators of high-quality contextualized token embeddings that improve on raw static embeddings. Those contextualized token embeddings are what’s used for tasks including named-entity recognition (NER), extractive text summarization, and text classification. In addition to producing token embeddings, language models can produce text embeddings that cover entire sentences or even documents. This empowers plenty of applications that will be shown in Part II of this book overing language model applications\n",
    "6. Before LLMs, word embedding methods like word2vec, GloVe, and fastText were popular. In language processing, this has largely been replaced with contextualized word embeddings produced by language models. The word2vec algorithm relies on two main ideas: skip-gram and negative sampling. It also uses contrastive training similar to the type we’ll see in Chapter 10.\n",
    "7. Embeddings are useful for creating and improving recommender systems as we discussed in the music recommender we built from curated song playlists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043fc47-13c7-4c63-9394-9c0f4ca34d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
