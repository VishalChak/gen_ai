{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca46b13-5bf7-4bdb-add8-45f60a9a1837",
   "metadata": {},
   "source": [
    "### llama_index support 40+ vector stores such\n",
    "- Chroma – Open-source, easy to use, and highly scalable for vector search, but limited to vector data and lacks complex relational query support\n",
    "- FAISS – Excellent for fast, in-memory similarity search and GPU acceleration, but requires manual setup and is not ideal for distributed or persistent storage\n",
    "- Pinecone – Fully managed cloud service with great scalability and metadata filtering, but requires an API key and incurs ongoing cloud costs.\n",
    "- Qdrant – Open-source, production-ready, and supports both self-hosted and cloud deployments, but requires separate infrastructure setup\n",
    "- Weaviate – Supports hybrid (dense + sparse) search and flexible schema, but self-hosting can be complex for beginners\n",
    "- Milvus – Highly scalable and open-source, good for big data, but setup and resource requirements can be significant.\n",
    "- Redis – Fast, in-memory, and easy to deploy for small to medium workloads, but limited by memory and not ideal for massive datasets.\n",
    "- Elasticsearch – Combines full-text and vector search for hybrid use cases, but can be resource-intensive and complex to tune for large-scale vector workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d570b-fef2-49c8-97f6-1590ca747bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c2d7374-d16d-4a0c-bf08-7df40de844fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.storage'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m llm_model = \u001b[33m\"\u001b[39m\u001b[33mcompound-beta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m embed_model = \u001b[33m\"\u001b[39m\u001b[33mlocal:BAAI/bge-small-en-v1.5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m rag = \u001b[43mRAGPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroq_api_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(rag.response(\u001b[33m\"\u001b[39m\u001b[33mWhat is in the documents?\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mRAGPipeline.__init__\u001b[39m\u001b[34m(self, model_name, api_key, embed_model, data_dir)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mself\u001b[39m.index = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mself\u001b[39m.query_engine = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mRAGPipeline._setup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ChromaDB setup\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstorage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvector_store\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChromaVectorStore\n\u001b[32m     25\u001b[39m chroma_client = chromadb.Client()\n\u001b[32m     26\u001b[39m chroma_collection = chroma_client.create_collection(\u001b[33m\"\u001b[39m\u001b[33mmy_collection\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_index.storage'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "class RAGPipeline:\n",
    "    def __init__(self, model_name, api_key, embed_model, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.embed_model = embed_model\n",
    "        self.llm = Groq(\n",
    "            model=model_name,\n",
    "            api_key=api_key\n",
    "        )\n",
    "        self.index = None\n",
    "        self.query_engine = None\n",
    "        self._setup()\n",
    "\n",
    "    def _setup(self):\n",
    "        Settings.llm = self.llm\n",
    "        Settings.embed_model = self.embed_model\n",
    "\n",
    "        # ChromaDB setup\n",
    "        import chromadb\n",
    "        from llama_index.storage.vector_store.chroma import ChromaVectorStore\n",
    "\n",
    "\n",
    "        chroma_client = chromadb.Client()\n",
    "        chroma_collection = chroma_client.create_collection(\"my_collection\")\n",
    "        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "        # Load documents\n",
    "        documents = SimpleDirectoryReader(self.data_dir).load_data()\n",
    "        self.index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "        # Fix: Typo in \"response_mode\" and use of invalid param\n",
    "        self.query_engine = self.index.as_query_engine(\n",
    "            similarity_top_k=3,\n",
    "            response_mode=\"compact\"  # Fixed typo here\n",
    "        )\n",
    "\n",
    "    def response(self, question):\n",
    "        return self.query_engine.query(question)\n",
    "\n",
    "# Run example\n",
    "if __name__ == \"__main__\":\n",
    "    groq_api_key = \"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\"\n",
    "    llm_model = \"compound-beta\"\n",
    "    embed_model = \"local:BAAI/bge-small-en-v1.5\"\n",
    "    rag = RAGPipeline(model_name=llm_model, api_key=groq_api_key, embed_model=embed_model, data_dir=\"data\")\n",
    "    print(rag.response(\"What is in the documents?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c214ae-0682-49d8-b0af-1181e07b36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "groq_api_key = \"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\"\n",
    "llm_model = \"compound-beta\"\n",
    "embed_model = \"local:BAAI/bge-small-en-v1.5\"\n",
    "rag = RAGPipeline(model_name = llm_model, api_key = groq_api_key , embed_model = embed_model, data_dir= \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02b9a4c-0fe4-4983-b094-a2b63dfcb29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vishal Babu is a data scientist.\n"
     ]
    }
   ],
   "source": [
    "print(rag.response(\"How is vishal babu and give soem details about him\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd545d29-0d19-419f-a67d-101787db43d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
